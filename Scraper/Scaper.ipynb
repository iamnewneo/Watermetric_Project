{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#just add to this list for each new player\n",
    "#player name : url\n",
    "query = \"https://www.google.co.in/search?q=%22yamuna+clean%22&tbm=nws&start=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#page = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.google.co.in/search?q=%22yamuna+clean%22&tbm=nws&start=0\n",
      "https://www.google.co.in/search?q=%22yamuna+clean%22&tbm=nws&start=10\n"
     ]
    }
   ],
   "source": [
    "#page = 0\n",
    "total = []\n",
    "results = []\n",
    "news_source_links = []\n",
    "for page in range(0,20,10):\n",
    "    print(query + str(page))\n",
    "    req  = requests.get(query + str(page), headers=headers)\n",
    "    soup = bs4.BeautifulSoup(req.text, \"html.parser\")\n",
    "    news_stories = soup.findAll(\"div\", { \"class\" : \"_cnc\" })\n",
    "    for news in news_stories:\n",
    "        single_news= {}\n",
    "        single_news[\"news_link\"] = news.find(\"a\")[\"href\"]\n",
    "        single_news[\"news_title\"] = news.find(\"a\").get_text()\n",
    "        single_news[\"news_text\"] = news.find(\"div\", {\"class\": \"st\"}).get_text()\n",
    "        sourceAndTime = news.contents[1].get_text().split(\"-\")\n",
    "        single_news[\"news_source\"], single_news[\"news_time\"] = sourceAndTime[0], \"-\".join(sourceAndTime[1:])\n",
    "        results.append(single_news)\n",
    "        news_source_links.append(single_news[\"news_link\"])\n",
    "        #page = page + 10\n",
    "        time.sleep(1)\n",
    "        #print(single_news)\n",
    "        #print(\"\\n\")\n",
    "    #print(type(news_stories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://swachhindia.ndtv.com/yamuna-clean-drive-gets-major-boost-by-ngt/',\n",
       " 'http://www.hindustantimes.com/delhi/rs-6-000-cr-yamuna-clean-up-project-hits-fund-hurdle/story-WOb2Wl6ZPx5tSU2dPUuILP.html',\n",
       " 'http://indianexpress.com/article/cities/delhi/clean-yamuna-treat-sewage-biodiversity-zone-2811518/',\n",
       " 'http://indianexpress.com/article/cities/delhi/contaminated-drain-load-getting-into-yamuna-river-delhi-pollution-panel-2922545/',\n",
       " 'http://www.thehindu.com/news/cities/Delhi/yamuna-cleanup-will-take-a-month-sri-sri/article8368449.ece',\n",
       " 'http://indianexpress.com/article/india/india-news-india/clean-up-part-iii-aap-govt-centre-join-hands-for-rs-825-cr-yamuna-action-plan-2789723/',\n",
       " 'http://indiatoday.intoday.in/story/ngts-yamuna-clean-up-plan-fails-to-take-off-one-year-on/1/578908.html',\n",
       " 'http://www.thehindu.com/news/national/delhi-chief-minister-arvind-kejriwal-seeks-sri-sris-help-to-clean-yamuna/article8349458.ece',\n",
       " 'http://indianexpress.com/article/india/india-news-india/delhi-government-presents-plan-for-cleaning-yamuna-to-centre-2817402/',\n",
       " 'http://www.dailymail.co.uk/indiahome/indianews/article-3228288/I-bathe-clean-Yamuna-36-months-Delhi-turn-private-sector-help-reviving-waterway.html',\n",
       " 'http://www.ndtv.com/delhi-news/spanish-envoy-meets-delhi-chief-minister-discusses-yamuna-clean-up-1230380',\n",
       " 'http://www.abplive.in/lifestyle/arvind-kejriwal-seeks-art-of-livings-help-to-clean-yamuna-305575',\n",
       " 'http://indianexpress.com/article/cities/mumbai/two-pune-air-boats-head-for-allahabad-to-clean-ganga-yamuna/',\n",
       " 'http://indiatoday.intoday.in/story/too-many-plans-hamper-yamuna-clean-up/1/459005.html',\n",
       " 'http://www.thehindu.com/news/national/green-tribunal-raps-centre-delhi-govt-on-yamuna-clean-up/article7571709.ece',\n",
       " 'http://www.dailymail.co.uk/indiahome/indianews/article-3136522/Yamuna-cleanup-committee-plans-pump-river-water-straight-Delhi-households.html',\n",
       " 'http://www.tribuneindia.com/news/delhi/swachh-yamuna-javadekar-vardhan-bjp-workers-join-hands-to-clean-river/175572.html',\n",
       " 'http://timesofindia.indiatimes.com/home/environment/pollution/Delhi-will-have-to-foot-Yamuna-clean-up-bill/articleshow/47208767.cms',\n",
       " 'http://www.dailymail.co.uk/indiahome/indianews/article-3190621/AAP-NDA-unite-clean-Yamuna-45-days.html',\n",
       " 'http://indianexpress.com/article/cities/delhi/ngt-warns-agencies-to-take-yamuna-clean-up-seriously/']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_source_links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run individual crawlers for websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def times_of_india(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"div\", class_=\"Normal\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    #print(article_header)\n",
    "    return article_text\n",
    "\n",
    "def the_hindu(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"div\", class_=\"articleLead\")\n",
    "    data=soup.find_all(\"p\", class_=\"body\")\n",
    "    #for element in article_header:\n",
    "        #article_text += element.get_text()\n",
    "    for element in data:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def daily_mail(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"p\", class_=\"mol-para-with-font\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def ndtv(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"div\", class_=\"ins_storybody\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def hindustan_times(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"p\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def indian_express(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"p\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def first_post(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"div\", class_=\"fullCont1\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def economic_times(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    article_header=soup.find_all(\"div\", class_=\"mod-economictimesarticletextwithadcpc mod-economictimesarticletext mod-articletext\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "\n",
    "def india_today(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    #article_header=soup.find_all(\"div\", class_=\"story_body_text\")\n",
    "    article_header=soup.findAll(\"div\", class_=\"right-story-container\")\n",
    "    for element in article_header:\n",
    "        article_text += element.get_text()\n",
    "    return article_text\n",
    "def other_site(src):\n",
    "    page  = requests.get(src, headers=headers)\n",
    "    soup = bs4.BeautifulSoup(page.text,\"html.parser\")\n",
    "    article_text = \"\"\n",
    "    body_with_html=soup.find(\"body\")\n",
    "#     for element in article_header:\n",
    "#         article_text += element.get_text()\n",
    "    return body_with_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#times_of_india_text(\"http://timesofindia.indiatimes.com/city/delhi/SC-Detail-steps-taken-to-keep-Yamuna-clean/articleshow/15525134.cms\")\n",
    "#the_hindu(\"http://www.thehindu.com/data/last-drop-drinking-water-sipping-poison/article8557720.ece\")\n",
    "#daily_mail(\"http://www.dailymail.co.uk/indiahome/indianews/article-3136522/Yamuna-cleanup-committee-plans-pump-river-water-straight-Delhi-households.html\")\n",
    "#indian_express(\"http://indianexpress.com/article/cities/chandigarh/chandigarh-e-water-atms-to-be-set-up-at-22-spots-in-city-2807861/\")\n",
    "#other_site(\"http://indianexpress.com/article/cities/chandigarh/chandigarh-e-water-atms-to-be-set-up-at-22-spots-in-city-2807861/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for result in results:\n",
    "    if \"timesofindia\" in result[\"news_link\"]:\n",
    "        article_text = times_of_india(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"thehindu\" in result[\"news_link\"]:\n",
    "        article_text = the_hindu(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"dailymail\" in result[\"news_link\"]:\n",
    "        article_text = daily_mail(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"indianexpress\" in result[\"news_link\"]:\n",
    "        article_text = indian_express(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"economictimes\" in result[\"news_link\"]:\n",
    "        article_text = economic_times(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"ndtv\" in result[\"news_link\"]:\n",
    "        article_text = ndtv(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"hindustantimes\" in result[\"news_link\"]:\n",
    "        article_text = hindustan_times(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"firstpost\" in result[\"news_link\"]:\n",
    "        article_text = first_post(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    elif \"indiatoday\" in result[\"news_link\"]:\n",
    "        article_text = india_today(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    else:\n",
    "        article_text = other_site(result[\"news_link\"])\n",
    "        result[\"article_text\"] = article_text\n",
    "    #print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Research paper link\n",
    "#http://link.springer.com/article/10.1007/s13201-011-0011-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\x81' in position 2155: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-a9d3c83da2e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdict_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mdict_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdict_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Kunal\\Anaconda3\\lib\\csv.py\u001b[0m in \u001b[0;36mwriterows\u001b[1;34m(self, rowdicts)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;31m# Guard Sniffer's type checking against builds that exclude complex()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Kunal\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\x81' in position 2155: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "keys = results[0].keys()\n",
    "with open('news_results.csv', 'w') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
